{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking heuristics & graph-based signals\n",
    "\n",
    "Implement at least one non-learned ranking heuristic (such as popularity, recency, or graph-based propagation) to serve as a baseline for real systems. Analyze its bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented three distinct rankers:\n",
    "1. `PopularityRanker`: global frequency-based baseline\n",
    "2. `RecencyRanker`: time-decayed popularity model\n",
    "3. `PersonalizedPageRankRanker` :  graph-based propagation method running on the user-item bipartite network\n",
    "These were evaluated using our custom `RecommenderEvaluator` framework from HW1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reuse the `MovieLensDataLoader` and train/val/test splits established in our previous evaluation framework, making them directly comparable to our MF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 797,758 | Val: 97,383 | Test: 105,068\n",
      "Loaded 1,000,209 ratings\n",
      "Loaded 3,883 movies\n",
      "Loaded 6,040 users\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "sys.path.append(\"../src/evaluation\")\n",
    "sys.path.append(\"../src/models\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "from collections import defaultdict\n",
    "from utils.data_loader import MovieLensDataLoader\n",
    "from evaluator import RecommenderEvaluator\n",
    "\n",
    "loader = MovieLensDataLoader()\n",
    "train, val, test = loader.load_splits()\n",
    "_, movies, _ = loader.load_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Popularity-Based Ranking**\n",
    "\n",
    "It ranks items solely by their global interaction count in the training set. It filters out items with fewer than a minimum threshold of ratings to avoid noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularityRanker:\n",
    "    \n",
    "    def __init__(self, train_df, min_ratings=5):\n",
    "        # count total interactions for each item\n",
    "        counts = train_df.groupby('item_id').size()\n",
    "\n",
    "        # store counts as a dictionary for fast lookups\n",
    "        self.scores = counts.to_dict()\n",
    "        self.min_ratings = min_ratings\n",
    "\n",
    "        # filter out unpopular items\n",
    "        self.ranked = counts[counts >= min_ratings].sort_values(ascending=False).index.tolist()\n",
    "    \n",
    "    def predict_for_user(self, user_id, k=10, train_df=None):\n",
    "        seen = set()\n",
    "\n",
    "        # extract items the user has already interacted with\n",
    "        if train_df is not None:\n",
    "            seen = set(train_df[train_df['user_id'] == user_id]['item_id'])\n",
    "        # keep items the user has not seen\n",
    "        recs = [(iid, self.scores[iid]) for iid in self.ranked if iid not in seen]\n",
    "\n",
    "        # return top-K\n",
    "        return recs[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recency-Weighted Ranking**\n",
    "\n",
    "It applies an exponential decay to historical interactions based on the timestamp. We set a half-life of 90 days. We check whether there is strong temporal drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecencyRanker:\n",
    "    \n",
    "    def __init__(self, train_df, half_life_days=90, min_ratings=5):\n",
    "        df = train_df.copy()\n",
    "\n",
    "        # find the most recent timestamp to act as the current time\n",
    "        max_ts = df['timestamp'].max()\n",
    "\n",
    "        # calculate how many days ago each interaction occurred\n",
    "        days_ago = (max_ts - df['timestamp']) / 86400\n",
    "\n",
    "        # apply exponential decay (older ratings get exponentially lower weights)\n",
    "        df['weight'] = np.exp(-np.log(2) * days_ago / half_life_days)\n",
    "        \n",
    "        # sum weights for each item to get its final score\n",
    "        item_scores = df.groupby('item_id')['weight'].sum()\n",
    "\n",
    "        # filtering with low num of interactions\n",
    "        item_counts = df.groupby('item_id').size()\n",
    "        item_scores = item_scores[item_counts >= min_ratings]\n",
    "        \n",
    "        self.scores = item_scores.to_dict()\n",
    "        self.ranked = item_scores.sort_values(ascending=False).index.tolist()\n",
    "    \n",
    "    def predict_for_user(self, user_id, k=10, train_df=None):\n",
    "        seen = set()\n",
    "        # extract items the user has already interacted with\n",
    "        if train_df is not None:\n",
    "            seen = set(train_df[train_df['user_id'] == user_id]['item_id'])\n",
    "        # keep items the user has not seen\n",
    "        recs = [(iid, self.scores[iid]) for iid in self.ranked if iid not in seen]\n",
    "\n",
    "        # return top-K\n",
    "        return recs[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graph-Based Propagation (personalized pagerank)**\n",
    "\n",
    "It constructs a bipartite graph of users and items connected by positive interactions (rating >= 4.0). It simulates a random walk starting from the target user, propagating preference scores through the network with a teleportation probability (`alpha=0.15`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalizedPageRankRanker:\n",
    "\n",
    "    def __init__(self, train_df, alpha=0.15, n_iterations=20, threshold=4.0):\n",
    "        self.alpha = alpha\n",
    "        self.n_iter = n_iterations\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # filteting only positive signals (>=4.0)\n",
    "        df = train_df[train_df['rating'] >= threshold]\n",
    "\n",
    "        # dimensions for the bipartite graph (users + items)\n",
    "        self.n_users = train_df['user_id'].max() + 1\n",
    "        self.n_items = train_df['item_id'].max() + 1\n",
    "        n = self.n_users + self.n_items\n",
    "        \n",
    "        # create undirected edges: user -> item AND item -> user\n",
    "        rows = np.concatenate([df['user_id'].values, self.n_users + df['item_id'].values])\n",
    "        cols = np.concatenate([self.n_users + df['item_id'].values, df['user_id'].values])\n",
    "        data = np.ones(len(rows), dtype=np.float32)\n",
    "        # build sparse adjacency matrix\n",
    "        adj = csr_matrix((data, (rows, cols)), shape=(n, n))\n",
    "        \n",
    "        # calculate out-degree for each node to normalize transition probabilities\n",
    "        degree = np.array(adj.sum(axis=1)).flatten()\n",
    "        degree[degree == 0] = 1\n",
    "        inv_deg = 1.0 / degree\n",
    "        # row-normalized stochastic transition matrix\n",
    "        self.transition = csr_matrix((inv_deg[adj.nonzero()[0]] * adj.data, adj.indices, adj.indptr), shape=(n, n))\n",
    "        \n",
    "        # items user has interacted with\n",
    "        self.user_seen = {}\n",
    "        for uid, g in train_df.groupby('user_id'):\n",
    "            self.user_seen[uid] = set(g['item_id'])\n",
    "    \n",
    "    def run_ppr(self, user_id):\n",
    "        n = self.n_users + self.n_items\n",
    "        # vector concentrated on target user\n",
    "        teleport = np.zeros(n, dtype=np.float32)\n",
    "        teleport[user_id] = 1.0\n",
    "        \n",
    "        scores = teleport.copy()\n",
    "        # power iteration\n",
    "        for _ in range(self.n_iter):\n",
    "            scores = (1 - self.alpha) * (self.transition.T @ scores) + self.alpha * teleport\n",
    "        # return only the scores corresponding to item nodes\n",
    "        return scores[self.n_users:]\n",
    "    \n",
    "    def predict_for_user(self, user_id, k=10, train_df=None):\n",
    "        if user_id >= self.n_users:\n",
    "            return []\n",
    "        # get raw PPR scores for all items\n",
    "        item_scores = self.run_ppr(user_id)\n",
    "        seen = self.user_seen.get(user_id, set())\n",
    "        # masking out seen items\n",
    "        for iid in seen:\n",
    "            if iid < len(item_scores):\n",
    "                item_scores[iid] = -np.inf\n",
    "        \n",
    "        # partition and top-K\n",
    "        top_k = np.argpartition(item_scores, -k)[-k:]\n",
    "        top_k = top_k[np.argsort(item_scores[top_k])[::-1]]\n",
    "        return [(int(i), float(item_scores[i])) for i in top_k if item_scores[i] > -np.inf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**\n",
    "\n",
    "We evaluate all three rankers using our `RecommenderEvaluator`. We look specifically at NDCG, Recall, and Coverage/Popularity bias to understand the distribution of the recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = PopularityRanker(train)\n",
    "rec = RecencyRanker(train, half_life_days=90)\n",
    "ppr = PersonalizedPageRankRanker(train, alpha=0.15, n_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Popularity - Evaluation results\n",
      "Ranking metrics:\n",
      "NDCG@ 5: 0.0437\n",
      "NDCG@10: 0.0490\n",
      "NDCG@20: 0.0615\n",
      "\n",
      "\n",
      "Relevance metrics (threshold=4.0):\n",
      "Recall@ 5: 0.0243\n",
      "Precision@ 5: 0.0425\n",
      "Recall@10: 0.0433\n",
      "Precision@10: 0.0393\n",
      "Recall@20: 0.0802\n",
      "Precision@20: 0.0352\n",
      "\n",
      "\n",
      "Diversity metrics:\n",
      "Coverage: 0.0513\n",
      "Popularity bias: 2085.91\n",
      "\n",
      "\n",
      "Recency - Evaluation results\n",
      "Ranking metrics:\n",
      "NDCG@ 5: 0.0380\n",
      "NDCG@10: 0.0438\n",
      "NDCG@20: 0.0547\n",
      "\n",
      "\n",
      "Relevance metrics (threshold=4.0):\n",
      "Recall@ 5: 0.0215\n",
      "Precision@ 5: 0.0383\n",
      "Recall@10: 0.0410\n",
      "Precision@10: 0.0353\n",
      "Recall@20: 0.0744\n",
      "Precision@20: 0.0315\n",
      "\n",
      "\n",
      "Diversity metrics:\n",
      "Coverage: 0.0436\n",
      "Popularity bias: 1796.94\n",
      "\n",
      "\n",
      "PPR - Evaluation results\n",
      "Ranking metrics:\n",
      "NDCG@ 5: 0.0475\n",
      "NDCG@10: 0.0544\n",
      "NDCG@20: 0.0667\n",
      "\n",
      "\n",
      "Relevance metrics (threshold=4.0):\n",
      "Recall@ 5: 0.0262\n",
      "Precision@ 5: 0.0463\n",
      "Recall@10: 0.0497\n",
      "Precision@10: 0.0428\n",
      "Recall@20: 0.0875\n",
      "Precision@20: 0.0375\n",
      "\n",
      "\n",
      "Diversity metrics:\n",
      "Coverage: 0.0578\n",
      "Popularity bias: 2052.98\n"
     ]
    }
   ],
   "source": [
    "evaluator = RecommenderEvaluator(train, test, k_values=[5, 10, 20])\n",
    "\n",
    "for name, model in [(\"Popularity\", pop), (\"Recency\", rec), (\"PPR\", ppr)]:\n",
    "    print(f\"\\n\")\n",
    "    metrics = evaluator.evaluate_model(model, model_name=name)\n",
    "    evaluator.print_metrics(metrics, model_name=name)\n",
    "\n",
    "evaluator.save_results(\"../experiments/results/heuristic_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model   NDCG@5  NDCG@10  NDCG@20  Recall@10  Coverage  Popularity_Bias\n",
      "Popularity 0.043673 0.049011 0.061451   0.043306  0.051282      2085.907599\n",
      "   Recency 0.037991 0.043834 0.054690   0.040981  0.043644      1796.937525\n",
      "       PPR 0.047532 0.054392 0.066679   0.049691  0.057829      2052.977525\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(evaluator.history)\n",
    "cols = ['Model', 'NDCG@5', 'NDCG@10', 'NDCG@20', 'Recall@10', 'Coverage', 'Popularity_Bias']\n",
    "print(results_df[[c for c in cols if c in results_df.columns]].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**\n",
    "\n",
    "##### Popularity-Based Ranking\n",
    "* assumes a \"wisdom of the crowd\" - if many people like it, it has universal quality\n",
    "* effective for pure cold-start scenarios or mainstream users. It proved to be a strong baseline on our dataset (NDCG@10 = 0.049)\n",
    "* fails for niche users. It also has poor catalog discovery (only 5.1% coverage)\n",
    "\n",
    "##### Recency-Weighted Popularity\n",
    "* encodes a temporal bias - assumes user preferences drift quickly and recent interactions are more relevant\n",
    "* fails on static catalogs. In MovieLens, penalizing classic movies simply because they are old actually degraded performance compared to raw popularity (NDCG@10 = 0.0438)\n",
    "\n",
    "##### Personalized PageRank\n",
    "* encodes a transitive similarity bias via graph topology - assumes preference flows through user-item community clusters\n",
    "* very competitive when the interaction graph is dense. PPR was our best-performing heuristic (NDCG@10 = 0.0544). It captured collaborative filtering signals and achieved the highest catalog coverage (5.78%)\n",
    "* fails on isolated cold-start items where the random walker cannot reach. It is also computationally expensive to run at inference time compared to simple popularity lookups"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
